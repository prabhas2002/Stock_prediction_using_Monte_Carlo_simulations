{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "752513be-7223-4adc-91f9-4b8e584429de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/keyur\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84770484-693b-4cff-9b6a-d556e9bd2eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39316725-df10-40e3-9235-aec90029328a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb5b1187-3a38-4d13-966b-40192aaf178a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved for AAPL (Dataset-A) at /data/home/prabhasreddy/MS_final/output/ComparsionGraphs/Dataset-A/AAPL_Dataset-A_Comparison.png\n",
      "Graph saved for TSLA (Dataset-A) at /data/home/prabhasreddy/MS_final/output/ComparsionGraphs/Dataset-A/TSLA_Dataset-A_Comparison.png\n",
      "Graph saved for GOOG (Dataset-A) at /data/home/prabhasreddy/MS_final/output/ComparsionGraphs/Dataset-A/GOOG_Dataset-A_Comparison.png\n",
      "Graph saved for MSFT (Dataset-A) at /data/home/prabhasreddy/MS_final/output/ComparsionGraphs/Dataset-A/MSFT_Dataset-A_Comparison.png\n",
      "Graph saved for AMZN (Dataset-A) at /data/home/prabhasreddy/MS_final/output/ComparsionGraphs/Dataset-A/AMZN_Dataset-A_Comparison.png\n",
      "Graph saved for AAPL (Dataset-B) at /data/home/prabhasreddy/MS_final/output/ComparsionGraphs/Dataset-B/AAPL_Dataset-B_Comparison.png\n",
      "Graph saved for TSLA (Dataset-B) at /data/home/prabhasreddy/MS_final/output/ComparsionGraphs/Dataset-B/TSLA_Dataset-B_Comparison.png\n",
      "Graph saved for GOOG (Dataset-B) at /data/home/prabhasreddy/MS_final/output/ComparsionGraphs/Dataset-B/GOOG_Dataset-B_Comparison.png\n",
      "Graph saved for MSFT (Dataset-B) at /data/home/prabhasreddy/MS_final/output/ComparsionGraphs/Dataset-B/MSFT_Dataset-B_Comparison.png\n",
      "Graph saved for AMZN (Dataset-B) at /data/home/prabhasreddy/MS_final/output/ComparsionGraphs/Dataset-B/AMZN_Dataset-B_Comparison.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base directories\n",
    "base_directory = \"/data/home/prabhasreddy/MS_final/output/\"\n",
    "dataset_directory = \"/data/home/prabhasreddy/MS_final/code base/Database/\"\n",
    "methods = [\"ARIMA\", \"JumpDiffusion\", \"MarkovChain\", \"MonteCarlo\"]\n",
    "datasets = {\n",
    "    \"Dataset-A\": {\n",
    "        \"start_date\": \"2015-01-02\",\n",
    "        \"plot_start_date\": \"2018-01-01\",  # Start plotting from 2020\n",
    "        \"end_date\": \"2020-02-26\",\n",
    "        \"pred_end_date\": \"2021-02-26\"\n",
    "    },\n",
    "    \"Dataset-B\": {\n",
    "        \"start_date\": \"2015-01-02\",\n",
    "        \"plot_start_date\": \"2019-01-01\",  # Start plotting from 2018\n",
    "        \"end_date\": \"2020-08-26\",\n",
    "        \"pred_end_date\": \"2021-02-26\"\n",
    "    }\n",
    "}\n",
    "companies = [\"AAPL\", \"TSLA\", \"GOOG\", \"MSFT\", \"AMZN\"]\n",
    "\n",
    "# Colors and line styles for methods and datasets\n",
    "styles = {\n",
    "    \"Train\": {\"color\": \"navy\", \"linestyle\": \"-\"},  # Navy blue for training data\n",
    "    \"Test\": {\"color\": \"deepskyblue\", \"linestyle\": \"-\"},  # Light blue for testing data\n",
    "    \"ARIMA\": {\"color\": \"darkred\", \"linestyle\": \"-\"},       # Dark red for ARIMA\n",
    "    \"JumpDiffusion\": {\"color\": \"forestgreen\", \"linestyle\": \"-\"},  # Forest green for Jump Diffusion\n",
    "    \"MarkovChain\": {\"color\": \"goldenrod\", \"linestyle\": \"-\"},   # Goldenrod for Markov Chain\n",
    "    \"MonteCarlo\": {\"color\": \"indigo\", \"linestyle\": \"-\"}       # Indigo for Monte Carlo\n",
    "}\n",
    "\n",
    "\n",
    "# Function to load training and testing data\n",
    "def load_train_test_data(company, dataset_params):\n",
    "    file_path = os.path.join(dataset_directory, f\"Pre_Processed_{company}.csv\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Data file not found for {company}: {file_path}\")\n",
    "        return None, None\n",
    "\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path, parse_dates=[\"Date\"])\n",
    "    data.set_index(\"Date\", inplace=True)\n",
    "\n",
    "    # Split into training and testing data\n",
    "    train_data = data.loc[dataset_params[\"plot_start_date\"]:dataset_params[\"end_date\"], \"Adj. Close\"]\n",
    "    test_data = data.loc[dataset_params[\"end_date\"]:dataset_params[\"pred_end_date\"], \"Adj. Close\"]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Function to plot comparison for each company\n",
    "def plot_comparison(company, dataset, train_data, test_data, predictions, output_dir):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot training and testing data with styles\n",
    "    plt.plot(\n",
    "        train_data.index, train_data, \n",
    "        label=\"Train Data\", \n",
    "        color=styles[\"Train\"][\"color\"], \n",
    "        linestyle=styles[\"Train\"][\"linestyle\"]\n",
    "    )\n",
    "    plt.plot(\n",
    "        test_data.index, test_data, \n",
    "        label=\"Test Data\", \n",
    "        color=styles[\"Test\"][\"color\"], \n",
    "        linestyle=styles[\"Test\"][\"linestyle\"]\n",
    "    )\n",
    "\n",
    "    # Plot predictions for each method with styles\n",
    "    for method, pred_data in predictions.items():\n",
    "        if not pred_data.empty:\n",
    "            plt.plot(\n",
    "                pred_data.index, pred_data['Predicted_Adj_Close'], \n",
    "                label=method, \n",
    "                color=styles[method][\"color\"], \n",
    "                linestyle=styles[method][\"linestyle\"]\n",
    "            )\n",
    "\n",
    "    # Customize and save plot\n",
    "    plt.title(f\"{company} Predictions Comparison ({dataset})\", fontsize=16)\n",
    "    plt.xlabel(\"Date\", fontsize=12)\n",
    "    plt.ylabel(\"Adj. Close Price\", fontsize=12)\n",
    "    plt.legend(loc=\"best\", fontsize=10)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot\n",
    "    output_file = os.path.join(output_dir, f\"{company}_{dataset}_Comparison.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "    print(f\"Graph saved for {company} ({dataset}) at {output_file}\")\n",
    "\n",
    "# Main function to generate comparison graphs\n",
    "def generate_graphs():\n",
    "    comparison_output_dir = os.path.join(base_directory, \"ComparsionGraphs\")\n",
    "    os.makedirs(comparison_output_dir, exist_ok=True)\n",
    "\n",
    "    for dataset, params in datasets.items():\n",
    "        dataset_output_dir = os.path.join(comparison_output_dir, dataset)\n",
    "        os.makedirs(dataset_output_dir, exist_ok=True)\n",
    "\n",
    "        for company in companies:\n",
    "            # Load training and testing data\n",
    "            train_data, test_data = load_train_test_data(company, params)\n",
    "            if train_data is None or test_data is None:\n",
    "                print(f\"Skipping {company} in {dataset} due to missing data.\")\n",
    "                continue\n",
    "\n",
    "            predictions = {}\n",
    "            for method in methods:\n",
    "                # Path to predictions for the current dataset, company, and method\n",
    "                pred_file = os.path.join(\n",
    "                    base_directory,\n",
    "                    method,\n",
    "                    \"predictions\",\n",
    "                    dataset,\n",
    "                    f\"{company}_predictions.csv\"\n",
    "                )\n",
    "                if os.path.exists(pred_file):\n",
    "                    predictions[method] = pd.read_csv(pred_file, index_col=\"Date\", parse_dates=True)\n",
    "                else:\n",
    "                    predictions[method] = pd.DataFrame()  # Empty DataFrame if file is missing\n",
    "\n",
    "            # Generate the comparison graph if at least one method has predictions\n",
    "            if any(not pred.empty for pred in predictions.values()):\n",
    "                plot_comparison(company, dataset, train_data, test_data, predictions, dataset_output_dir)\n",
    "            else:\n",
    "                print(f\"No predictions available for {company} in {dataset}\")\n",
    "\n",
    "# Generate the comparison graphs\n",
    "generate_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec637877-2c73-4240-ad7d-16d097b5b9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6efbd89d-e677-4ff8-a465-6f95c9a3cb09",
   "metadata": {},
   "source": [
    "''Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38ba003-fe4d-4e15-918e-a41ac3e06639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics comparison graph saved for AAPL (Dataset-A) at /Users/keyur/Downloads/Phase2 modeling and simulation/output/MetricsComparisonGraphs/Dataset-A/AAPL_Dataset-A_MetricsComparison.png\n",
      "Metrics comparison graph saved for TSLA (Dataset-A) at /Users/keyur/Downloads/Phase2 modeling and simulation/output/MetricsComparisonGraphs/Dataset-A/TSLA_Dataset-A_MetricsComparison.png\n",
      "Metrics comparison graph saved for GOOG (Dataset-A) at /Users/keyur/Downloads/Phase2 modeling and simulation/output/MetricsComparisonGraphs/Dataset-A/GOOG_Dataset-A_MetricsComparison.png\n",
      "Metrics comparison graph saved for MSFT (Dataset-A) at /Users/keyur/Downloads/Phase2 modeling and simulation/output/MetricsComparisonGraphs/Dataset-A/MSFT_Dataset-A_MetricsComparison.png\n",
      "Metrics comparison graph saved for AMZN (Dataset-A) at /Users/keyur/Downloads/Phase2 modeling and simulation/output/MetricsComparisonGraphs/Dataset-A/AMZN_Dataset-A_MetricsComparison.png\n",
      "Metrics comparison graph saved for AAPL (Dataset-B) at /Users/keyur/Downloads/Phase2 modeling and simulation/output/MetricsComparisonGraphs/Dataset-B/AAPL_Dataset-B_MetricsComparison.png\n",
      "Metrics comparison graph saved for TSLA (Dataset-B) at /Users/keyur/Downloads/Phase2 modeling and simulation/output/MetricsComparisonGraphs/Dataset-B/TSLA_Dataset-B_MetricsComparison.png\n",
      "Metrics comparison graph saved for GOOG (Dataset-B) at /Users/keyur/Downloads/Phase2 modeling and simulation/output/MetricsComparisonGraphs/Dataset-B/GOOG_Dataset-B_MetricsComparison.png\n",
      "Metrics comparison graph saved for MSFT (Dataset-B) at /Users/keyur/Downloads/Phase2 modeling and simulation/output/MetricsComparisonGraphs/Dataset-B/MSFT_Dataset-B_MetricsComparison.png\n",
      "Metrics comparison graph saved for AMZN (Dataset-B) at /Users/keyur/Downloads/Phase2 modeling and simulation/output/MetricsComparisonGraphs/Dataset-B/AMZN_Dataset-B_MetricsComparison.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Base directory for metrics\n",
    "base_directory = \"/Users/keyur/Downloads/Phase2 modeling and simulation/output/\"\n",
    "methods = [\"ARIMA\", \"JumpDiffusion\", \"MarkovChain\", \"MonteCarlo\"]\n",
    "datasets = [\"Dataset-A\", \"Dataset-B\"]\n",
    "metrics_types = [\"MSE\", \"MAE\", \"RMSE\", \"MAPE\"]\n",
    "\n",
    "# Function to load metrics for a specific method and dataset\n",
    "def load_metrics(method, dataset):\n",
    "    metrics_file = os.path.join(base_directory, method, \"metrics\", dataset, \"metrics.csv\")\n",
    "    if os.path.exists(metrics_file):\n",
    "        metrics_data = pd.read_csv(metrics_file)\n",
    "        return metrics_data\n",
    "    else:\n",
    "        print(f\"Metrics file not found: {metrics_file}\")\n",
    "        return None\n",
    "\n",
    "# Function to scale metrics (Min-Max Scaling)\n",
    "def scale_metrics(metrics_data):\n",
    "    scaled_data = {}\n",
    "    for metric_idx, metric in enumerate(metrics_types):\n",
    "        # Collect all metric values across methods\n",
    "        all_values = [\n",
    "            metrics_data[method][metric_idx]\n",
    "            for method in metrics_data if method in metrics_data\n",
    "        ]\n",
    "        if all_values:  # If metric values exist\n",
    "            min_value = min(all_values)\n",
    "            max_value = max(all_values)\n",
    "            range_value = max_value - min_value if max_value > min_value else 1\n",
    "\n",
    "            # Scale each value to [0, 1]\n",
    "            for method in metrics_data:\n",
    "                metrics_data[method][metric_idx] = (\n",
    "                    (metrics_data[method][metric_idx] - min_value) / range_value\n",
    "                )\n",
    "        scaled_data[metric] = metrics_data\n",
    "    return metrics_data\n",
    "\n",
    "# Function to plot metrics comparison\n",
    "def plot_metrics_comparison(metrics_data, company, dataset, output_dir):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Create a bar chart for each metric\n",
    "    bar_width = 0.2\n",
    "    x = range(len(metrics_types))\n",
    "\n",
    "    for i, method in enumerate(methods):\n",
    "        if method in metrics_data:\n",
    "            method_metrics = metrics_data[method]\n",
    "            plt.bar(\n",
    "                [pos + i * bar_width for pos in x], \n",
    "                method_metrics, \n",
    "                width=bar_width, \n",
    "                label=method\n",
    "            )\n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.title(f\"{company} Metrics Comparison ({dataset})\", fontsize=16)\n",
    "    plt.xlabel(\"Metrics (Scaled)\", fontsize=12)\n",
    "    plt.ylabel(\"Scaled Values [0, 1]\", fontsize=12)\n",
    "    plt.xticks([pos + bar_width for pos in x], metrics_types)\n",
    "    plt.legend(loc=\"best\", fontsize=10)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Add note about scaling\n",
    "    plt.figtext(0.5, -0.05, \"Note: Values scaled using Min-Max normalization.\", ha=\"center\", fontsize=10)\n",
    "\n",
    "    # Save the plot\n",
    "    output_file = os.path.join(output_dir, f\"{company}_{dataset}_MetricsComparison.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "    print(f\"Metrics comparison graph saved for {company} ({dataset}) at {output_file}\")\n",
    "\n",
    "# Main function to generate metrics comparison graphs\n",
    "def generate_metrics_comparison():\n",
    "    metrics_output_dir = os.path.join(base_directory, \"MetricsComparisonGraphs\")\n",
    "    os.makedirs(metrics_output_dir, exist_ok=True)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        dataset_output_dir = os.path.join(metrics_output_dir, dataset)\n",
    "        os.makedirs(dataset_output_dir, exist_ok=True)\n",
    "\n",
    "        for company in [\"AAPL\", \"TSLA\", \"GOOG\", \"MSFT\", \"AMZN\"]:\n",
    "            metrics_data = {}\n",
    "            for method in methods:\n",
    "                # Load metrics for the current method and dataset\n",
    "                metrics = load_metrics(method, dataset)\n",
    "                if metrics is not None:\n",
    "                    # Extract metrics for the current company\n",
    "                    company_metrics = metrics[metrics[\"Stock\"] == company]\n",
    "                    if not company_metrics.empty:\n",
    "                        metrics_data[method] = [\n",
    "                            company_metrics[metric].values[0] for metric in metrics_types\n",
    "                        ]\n",
    "\n",
    "            # Scale the metrics for better visualization\n",
    "            metrics_data = scale_metrics(metrics_data)\n",
    "\n",
    "            # Plot metrics comparison if we have data for at least one method\n",
    "            if metrics_data:\n",
    "                plot_metrics_comparison(metrics_data, company, dataset, dataset_output_dir)\n",
    "            else:\n",
    "                print(f\"No metrics data available for {company} in {dataset}\")\n",
    "\n",
    "# Generate the metrics comparison graphs\n",
    "generate_metrics_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e343f2d-4cb6-430a-aa9f-59e3fc123129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
